# backend/app/api/v1/endpoints/products.py

from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List
from pydantic import BaseModel

from transformers import AutoProcessor, AutoModel
import torch
import torch.nn.functional as F

from app.db.database import get_db
from app.schemas.product import Product, ProductCreate
from app.crud import crud_product

router = APIRouter()

# --- AI ëª¨ë¸ ë¡œë“œ ---
MODEL_NAME = 'koclip/koclip-base-pt'
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

print("ğŸ”„ AI ëª¨ë¸ ë¡œë”© ì¤‘...")
try:
    model = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)
    processor = AutoProcessor.from_pretrained(MODEL_NAME)
    print("âœ… AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
except Exception as e:
    print(f"âŒ AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    model = None
    processor = None

class SearchRequest(BaseModel):
    query: str

# ---------------------------------------------------------

def extract_filters(query: str) -> dict:
    """ì¿¼ë¦¬ì—ì„œ ì„±ë³„, ê³„ì ˆ ì¶”ì¶œ"""
    query_lower = query.lower()
    
    # ì„±ë³„ ê°ì§€
    gender = None
    if any(word in query_lower for word in ["ì—¬ì„±", "ì—¬ì", "ìš°ë¨¼", "ì—¬", "ì—¬ì„±êº¼", "ì—¬ìêº¼"]):
        gender = "ì—¬ì„±"
    elif any(word in query_lower for word in ["ë‚¨ì„±", "ë‚¨ì", "ë§¨ì¦ˆ", "ë‚¨", "ë‚¨ì„±êº¼", "ë‚¨ìêº¼"]):
        gender = "ë‚¨ì„±"
    
    # ê³„ì ˆ ê°ì§€
    season = None
    if "ê²¨ìš¸" in query_lower:
        season = "ê²¨ìš¸"
    elif "ì—¬ë¦„" in query_lower:
        season = "ì—¬ë¦„"
    elif "ë´„" in query_lower:
        season = "ë´„"
    elif "ê°€ì„" in query_lower:
        season = "ê°€ì„"
    elif "ì‚¬ê³„ì ˆ" in query_lower or "4ê³„ì ˆ" in query_lower:
        season = "ì‚¬ê³„ì ˆ"
    
    return {
        "gender": gender,
        "season": season
    }


def extract_core_keywords(query: str, gender: str = None) -> list:
    """í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ (ë¶ˆìš©ì–´/ì¡°ì‚¬ ì œê±°)"""
    # ë¶ˆìš©ì–´
    stopwords = {
        'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì˜', 'ì—', 'ì™€', 'ê³¼',
        'ì…ì„', 'í• ë•Œ', 'ë•Œ', 'í• ', 'ì¶”ì²œ', 'ì¶”ì²œí•´ì¤˜', 'í•´ì¤˜', 'ì¢€',
        'ì—ì„œ', 'ì…ì„ë§Œí•œ', 'ì…ê¸°', 'ì¢‹ì€', 'ì í•©í•œ', 'ì–´ìš¸ë¦¬ëŠ”',
        'ì…ì„ì˜·', 'ì˜·', 'êº¼ë¡œ', 'ê²ƒ', 'ê±°', 'ë‚¨ì„±êº¼ë¡œ', 'ì—¬ì„±êº¼ë¡œ', 'ë‚¨ìêº¼ë¡œ', 'ì—¬ìêº¼ë¡œ'
    }
    
    # â˜…â˜…â˜… í‚¤ì›Œë“œ í™•ì¥ ì‚¬ì „ (ë¶€ë¶„ ë§¤ì¹­ìš©) â˜…â˜…â˜…
    keyword_patterns = {
        # ìš´ë™ ê´€ë ¨
        "ìš´ë™": ["ë ˆê¹…ìŠ¤", "ì‡¼ì¸ ", "íƒ€ì´ì¦ˆ"],
        "íŠ¸ë ˆì´ë‹": ["ë ˆê¹…ìŠ¤", "ì‡¼ì¸ ", "íƒ€ì´ì¦ˆ"],
        "í—¬ìŠ¤": ["ë ˆê¹…ìŠ¤", "ì‡¼ì¸ ", "íƒ€ì´ì¦ˆ", "ì»´í”„ë ˆì…˜"],
        "ìš”ê°€": ["ë ˆê¹…ìŠ¤"],
        "í•„ë¼í…ŒìŠ¤": ["ë ˆê¹…ìŠ¤"],
        "ëŸ¬ë‹": ["ì‡¼ì¸ ", "ë ˆê¹…ìŠ¤"],
        "ì¡°ê¹…": ["ì‡¼ì¸ ", "ë ˆê¹…ìŠ¤"],
        "ë‹¬ë¦¬ê¸°": ["ì‡¼ì¸ ", "ë ˆê¹…ìŠ¤"],
        
        # â˜… ê³„ì ˆ/ë‚ ì”¨ (ë¶€ë¶„ ë§¤ì¹­)
        "ì¶”": ["íŒ¨ë”©", "ë¡±íŒ¨ë”©", "ì½”íŠ¸", "ìì¼“"],  # ì¶”ì›Œ, ì¶”ìš´, ì¶¥ë‹¤, ì¶”ìš¸ë•Œ
        "ì–¼ì–´": ["íŒ¨ë”©", "ë¡±íŒ¨ë”©", "ì½”íŠ¸", "ìì¼“"],  # ì–¼ì–´ì£½ì„, ì–¼ì–´ì£½ê² 
        "ê²¨ìš¸": ["íŒ¨ë”©", "ë¡±íŒ¨ë”©", "ì½”íŠ¸", "ìì¼“"],
        "ë”": ["ì‡¼ì¸ "],  # ë”ì›Œ, ë”ìš´, ë¥ë‹¤, ë”ì›Œì£½
        "ë”ì›Œ": ["ì‡¼ì¸ "],  # ë”ì›Œì£½ê² ë‹¤, ë”ì›Œì£½ì„
        "ì—¬ë¦„": ["ì‡¼ì¸ "],
        "ì‹œì›": ["ì‡¼ì¸ "],
        "ë”°ëœ»": ["íŒ¨ë”©", "ë¡±íŒ¨ë”©", "ì½”íŠ¸", "ìì¼“"],
        "í¬ê·¼": ["íŒ¨ë”©", "ë¡±íŒ¨ë”©", "ì½”íŠ¸", "ìì¼“"],
        "ë•€": ["ì‡¼ì¸ "],
        
        # ì•„ì›ƒë„ì–´
        "ë“±ì‚°": ["ì•„ë…¸ë½", "ìì¼“", "íŒ¬ì¸ "],
        "ìº í•‘": ["ì•„ë…¸ë½", "ìì¼“"],
        "ì•„ì›ƒë„ì–´": ["ì•„ë…¸ë½", "ìì¼“", "íŒ¬ì¸ "],
        
        # ì„±ë³„ ê´€ë ¨
        "ì—¬ì": ["ì—¬ì„±"],
        "ë‚¨ì": ["ë‚¨ì„±"],
        "ì—¬ì„±": ["ì—¬ì„±"],
        "ë‚¨ì„±": ["ë‚¨ì„±"],
        
        # ìŠ¤íƒ€ì¼
        "í¸í•œ": ["ë§¨íˆ¬ë§¨", "í›„ë“œ", "ì¡°ê±°íŒ¬ì¸ "],
        "ìºì£¼ì–¼": ["ë§¨íˆ¬ë§¨", "í›„ë“œ", "ì²­ë°”ì§€"],
        "ì •ì¥": ["ì…”ì¸ ", "ë¸”ë¼ìš°ìŠ¤", "ìŠ¬ë™ìŠ¤", "ìì¼“"],
        
        # ìƒí™©ë³„
        "ë¹„": ["ì•„ë…¸ë½", "ìì¼“"],
        "ëˆˆ": ["íŒ¨ë”©", "ë¡±íŒ¨ë”©"],
    }
    
    # â˜…â˜…â˜… ìš©ë„ë³„ (ì„±ë³„ì— ë”°ë¼) â˜…â˜…â˜…
    if gender == "ë‚¨ì„±":
        keyword_patterns.update({
            "ë°ì´íŠ¸": ["ì…”ì¸ ", "ìì¼“", "ìŠ¬ë™ìŠ¤"],
            "ì†Œê°œíŒ…": ["ì…”ì¸ ", "ìì¼“", "ìŠ¬ë™ìŠ¤"],
            "ì¶œê·¼": ["ì…”ì¸ ", "ìŠ¬ë™ìŠ¤", "ìì¼“"],
            "ë©´ì ‘": ["ì…”ì¸ ", "ìŠ¬ë™ìŠ¤", "ìì¼“"],
        })
    elif gender == "ì—¬ì„±":
        keyword_patterns.update({
            "ë°ì´íŠ¸": ["ì›í”¼ìŠ¤", "ë¸”ë¼ìš°ìŠ¤", "ìŠ¤ì»¤íŠ¸"],
            "ì†Œê°œíŒ…": ["ì›í”¼ìŠ¤", "ë¸”ë¼ìš°ìŠ¤", "ìŠ¤ì»¤íŠ¸"],
            "ì¶œê·¼": ["ë¸”ë¼ìš°ìŠ¤", "ìŠ¤ì»¤íŠ¸", "ìì¼“"],
            "ë©´ì ‘": ["ë¸”ë¼ìš°ìŠ¤", "ìŠ¤ì»¤íŠ¸", "ìì¼“"],
        })
    else:
        keyword_patterns.update({
            "ë°ì´íŠ¸": ["ì…”ì¸ ", "ìì¼“"],
            "ì†Œê°œíŒ…": ["ì…”ì¸ ", "ìì¼“"],
            "ì¶œê·¼": ["ì…”ì¸ ", "ìì¼“"],
            "ë©´ì ‘": ["ì…”ì¸ ", "ìì¼“"],
        })
    
    words = query.split()
    keywords = []
    
    for word in words:
        # ë¶ˆìš©ì–´ ì œê±°
        if word in stopwords or len(word) <= 1:
            continue
        
        # â˜…â˜…â˜… ë¶€ë¶„ ë§¤ì¹­ìœ¼ë¡œ í™•ì¥ â˜…â˜…â˜…
        matched = False
        for pattern, expanded in keyword_patterns.items():
            if pattern in word:  # â† ë¶€ë¶„ ë§¤ì¹­
                keywords.extend(expanded)
                matched = True
                break
        
        if not matched:
            keywords.append(word)
    
    # ì¤‘ë³µ ì œê±°
    return list(set(keywords))


# 1. í…ìŠ¤íŠ¸ ê²€ìƒ‰ API
@router.post("/search", response_model=List[Product])
async def search_products(
    request: SearchRequest,
    db: AsyncSession = Depends(get_db)
):
    query = request.query
    clean_query = query.replace("ì¶”ì²œí•´ì¤˜", "").replace("ì¶”ì²œ", "").strip()
    if not clean_query: 
        clean_query = query

    print(f"ğŸ” ê²€ìƒ‰ì–´: {query} -> {clean_query}")

    if not model or not processor:
        raise HTTPException(status_code=500, detail="AI Model not loaded")

    # í•„í„° ì¶”ì¶œ
    filters = extract_filters(clean_query)
    print(f"ğŸ¯ í•„í„°: ì„±ë³„={filters['gender']}, ê³„ì ˆ={filters['season']}")

    # í…ìŠ¤íŠ¸ â†’ ë²¡í„°
    inputs = processor(
        text=clean_query, 
        return_tensors="pt", 
        padding=True, 
        truncation=True,
        max_length=77
    ).to(DEVICE)
    
    text_features = model.get_text_features(**inputs)
    text_features = F.normalize(text_features, p=2, dim=1)
    query_vector = text_features[0].cpu().detach().numpy().tolist()

    # â˜… gender ì „ë‹¬ (í•µì‹¬!)
    core_keywords = extract_core_keywords(clean_query, gender=filters['gender'])
    print(f"ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ: {core_keywords}")
    
    # ì¿¼ë¦¬ íƒ€ì… ë¶„ì„
    if len(core_keywords) == 1 and core_keywords[0] in ["ë ˆê¹…ìŠ¤", "íŒ¨ë”©", "ìì¼“", "ì›í”¼ìŠ¤", "ìŠ¤ì»¤íŠ¸", "ì‡¼ì¸ "]:
        # ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰
        print(f"ğŸ“Œ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ëª¨ë“œ")
        results = await crud_product.search_products_by_text_vector(
            db, 
            query_vector, 
            top_k=20,
            threshold=0.35,
            keywords=core_keywords,
            season_filter=filters['season'],
            gender_filter=filters['gender']
        )
    elif len(core_keywords) >= 1:
        # ë³µí•© ê²€ìƒ‰
        print(f"ğŸ“Œ ë³µí•© ê²€ìƒ‰ ëª¨ë“œ")
        results = await crud_product.search_products_by_text_vector(
            db, 
            query_vector, 
            top_k=20,
            threshold=0.30,
            keywords=core_keywords,
            season_filter=filters['season'],
            gender_filter=filters['gender']
        )
    else:
        # ë²¡í„° ê²€ìƒ‰ë§Œ
        print(f"ğŸ“Œ ë²¡í„° ê²€ìƒ‰ ëª¨ë“œ")
        results = await crud_product.search_products_by_text_vector(
            db, 
            query_vector, 
            top_k=20,
            threshold=0.35,
            keywords=None,
            season_filter=filters['season'],
            gender_filter=filters['gender']
        )
    
    return results


# 2. ë‹¤ë¥¸ ìƒ‰ìƒ ë³´ê¸° API
@router.get("/{product_id}/colors", response_model=List[Product])
async def get_color_variations(
    product_id: int, 
    db: AsyncSession = Depends(get_db)
):
    current_product = await crud_product.get_product(db, product_id)
    if not current_product:
        raise HTTPException(status_code=404, detail="Product not found")

    variations = await crud_product.get_similar_products_by_name(
        db, 
        current_product.name, 
        product_id
    )
    return variations


# 3. ìƒí’ˆ ìƒì„± API
@router.post("/", response_model=Product)
async def create_new_product(
    product: ProductCreate, 
    db: AsyncSession = Depends(get_db)
):
    return await crud_product.create_product(db=db, product=product)


# 4. ìƒí’ˆ ëª©ë¡ ì¡°íšŒ API
@router.get("/", response_model=List[Product])
async def read_all_products(
    skip: int = 0, 
    limit: int = 100, 
    db: AsyncSession = Depends(get_db)
):
    products = await crud_product.get_products(db, skip=skip, limit=limit)
    return products


# 5. íŠ¹ì • ìƒí’ˆ ì¡°íšŒ API
@router.get("/{product_id}", response_model=Product)
async def read_single_product(
    product_id: int, 
    db: AsyncSession = Depends(get_db)
):
    db_product = await crud_product.get_product(db, product_id=product_id)
    if db_product is None:
        raise HTTPException(status_code=404, detail="Product not found")
    return db_product